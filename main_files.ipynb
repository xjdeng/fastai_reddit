{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: you may need to run the following in administrator mode in Windows, esp if you had to install spacy's language models\n",
    "# as admin.  See the README for details.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "import spacy\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "import praw\n",
    "import re\n",
    "import random\n",
    "from path import Path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize key variables here\n",
    "credential_file = \"credentials.key\"\n",
    "targetuser = \"ryan_holiday\" #User you are targetting, NOT necessarily your username (unless you want to do this on yourself)\n",
    "test_portion = 0.1 #What fraction of the user's posts and submissions to use as the test set?\n",
    "bs = 4\n",
    "bptt = 70\n",
    "em_sz = 200  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers\n",
    "train_dir = \"train/\"\n",
    "test_dir = \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(credential_file, 'r') as f:\n",
    "        creds = f.read().split('\\n')\n",
    "    personal = creds[0]\n",
    "    secret = creds[1]\n",
    "    username = creds[2]\n",
    "    password = creds[3]\n",
    "except OSError as e:\n",
    "    print(\"You didn't create a credential file! Please see sample_credentials.key\")\n",
    "    print(\"Then go to http://www.storybench.org/how-to-scrape-reddit-with-python/\")\n",
    "    print(\"And register a new app named fastai_reddit in your reddit account.\")\n",
    "    print(\"And insert the values into sample_credentials.key and save it as {}.\".format(credential_file))\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=personal, client_secret=secret, user_agent='fastai_reddit', username=username, \\\n",
    "                     password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noquotes(text):\n",
    "    return re.sub(\">.+?(\\n|$)\",\"\",text).replace(\"\\\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to stop this.\n"
     ]
    }
   ],
   "source": [
    "# Test that our Reddit connection works\n",
    "subreddit = reddit.subreddit('Nootropics')\n",
    "test = list(subreddit.top(limit=10))[0]\n",
    "print(test.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read it however you like my friend. It's designed to be one page a day (and tied to the day's date) but it will work in just about any form. \n",
      "If you fear getting caught doing something, it's probably a sign you shouldn't be doing it. \n"
     ]
    }
   ],
   "source": [
    "# Test getting the latest 2 comments from the user\n",
    "# See: https://www.reddit.com/r/redditdev/comments/5gt42t/praw_getting_users_last_1000_comments_causing/ \n",
    "user = reddit.redditor(targetuser)\n",
    "for comment in user.comments.new(limit=2):\n",
    "    print(noquotes(comment.body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've just finished reading Thirteen Days as well as a number of interesting articles that attempt to \"correct the record\" about the Cuban Missile Crisis (including [this one from The Atlantic](https://www.theatlantic.com/magazine/archive/2013/01/the-real-cuban-missile-crisis/309190/?single_page=true)). Here is where I am confused. In Thirteen Days, RFK makes the case that Kennedy had never really wanted the Jupiter missiles in Turkey, that he had repeatedly asked for them to be removed, and possibly even thought they already had been. Therefore he was frustrated when Khrushchev demanded their removal because it was clear that the US's hardline position re: Cuba was less compelling with their existence. (Ultimately he ended up trading away their removal).\n",
      "\n",
      "However, in a lot of contrarian histories I've read blame Kennedy for starting the crisis by placing the missiles there in 1961 (even though plans appear to predate his presidency) and more or less put the responsibility on him for pushing the USSR into a position where they needed a check on the US in Cuba. \n",
      "\n",
      "My question for the historians here is who is correct? It appears the missiles were never particularly effective or advanced in the first place, so why did they go up, why were they left and who does the fault lie with?\n",
      "\n",
      "Thank you!\n",
      "I just finished reading Olmstead's [*A Journey Through Texas*](http://www.nebraskapress.unl.edu/bison-books/9780803286207/)*,* which he wrote while touring the state on horseback from 1856\\-1857. It's very interesting and surprisingly a good deal of the observations stand true today. The only part I edited out of this section was his comparison of slave prices \\(which he was not a supporter of\\):\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test getting the latest 2 submissions from the user\n",
    "# See: https://www.reddit.com/r/redditdev/comments/38wzzm/praw_how_to_get_submission_text/\n",
    "# TODO: write a function to remove quoted text between a \">\" and a new line\n",
    "for sub in user.submissions.new(limit=2):\n",
    "    print(noquotes(sub.selftext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for comment in user.comments.new(limit=None):\n",
    "    text.append(noquotes(comment.body))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs = []\n",
    "for sub in user.submissions.new(limit=None):\n",
    "    newsub = noquotes(sub.selftext)\n",
    "    if len(newsub) > 0:\n",
    "        subs.append(newsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltext = text + subs\n",
    "random.shuffle(alltext)\n",
    "split = round(test_portion*len(alltext))\n",
    "test = alltext[0:split]\n",
    "train = alltext[split:]\n",
    "train_p = path(train_dir)\n",
    "test_p = path(test_dir)\n",
    "train_p.mkdir_p()\n",
    "test_p.mkdir_p()\n",
    "for f in train_p.files() + test_p.files():\n",
    "    f.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,t in enumerate(train):\n",
    "    with open(train_dir + str(i) + \".txt\", \"w\") as f:\n",
    "        f.write(str(str(t).encode('ascii', 'ignore')))\n",
    "\n",
    "for i,t in enumerate(test):\n",
    "    with open(test_dir + str(i) + \".txt\", \"w\") as f:\n",
    "        f.write(str(str(t).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(954, 106)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXTS = data.Field(lower=True, tokenize=\"spacy\")\n",
    "FILES = dict(train=train_dir, validation=test_dir, test=test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = LanguageModelData.from_text_files(\"./\", TEXTS, **FILES, bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2c733e85e44dff9cdc2bd0c3cff374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      4.647748   4.522188  \n",
      "    1      4.626875   5.155661                                                                                         \n",
      "    2      4.626266   4.556951                                                                                         \n",
      "    3      4.640644   4.533238                                                                                         \n",
      "    4      4.626163   4.516031                                                                                         \n",
      "    5      4.603915   4.516233                                                                                         \n",
      "    6      4.612507   4.519444                                                                                         \n",
      "    7      4.634662   4.525259                                                                                         \n",
      "    8      4.614674   4.7816                                                                                           \n",
      "    9      4.617729   4.531812                                                                                         \n",
      "    10     4.597134   4.558728                                                                                         \n",
      "    11     4.617511   4.53299                                                                                          \n",
      "    12     4.622311   4.526802                                                                                         \n",
      "    13     4.604331   4.521848                                                                                         \n",
      "    14     4.621397   4.516058                                                                                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.51606])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI custom",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
